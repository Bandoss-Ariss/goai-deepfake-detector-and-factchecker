{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "# import dlib\n",
    "#from mtcnn import MTCNN\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, SubsetRandomSampler\n",
    "from torchvision.models import alexnet, AlexNet_Weights, vgg16, VGG16_Weights\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "from ray import tune\n",
    "from ray import train\n",
    "from ray.tune.search.hebo import HEBOSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_real_path = '/teamspace/studios/deepfake-image-detection-resnet/dataset/real'\n",
    "dest_real_path = '/videos/Real'\n",
    "\n",
    "source_fake_path = '/teamspace/studios/deepfake-image-detection-resnet/dataset/fake'\n",
    "dest_fake_path = '/videos/Fake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.exists(source_real_path):\n",
    "    print(\"Dataset found!\")\n",
    "else:\n",
    "    print(\"Dataset not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history_dic):\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n",
    "    \n",
    "    ax1.plot(history_dic['train_loss'], label='Training Loss', color='blue')\n",
    "    ax1.plot(history_dic['val_loss'], label='Validation Loss', color='red')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(history_dic['train_acc'], label='Training Accuracy', color='blue')\n",
    "    ax2.plot(history_dic['val_acc'], label='Validation Accuracy', color='red')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate(model, test_ds):\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([], dtype=torch.int64).to(device)\n",
    "    y_pred = torch.tensor([], dtype=torch.int64).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_ds):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x)\n",
    "            predictions = torch.where(output >= 0.5, 1, 0)\n",
    "    \n",
    "            # Accumulate true labels and predictions\n",
    "            y_true = torch.cat((y_true, y), dim=0)\n",
    "            y_pred = torch.cat((y_pred, predictions), dim=0)\n",
    "\n",
    "        y_true = y_true.cpu()\n",
    "        y_pred = y_pred.cpu()\n",
    "            \n",
    "            \n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=[\"Real\", \"Fake\"])\n",
    "    print(report)\n",
    "\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    ax = sns.heatmap(matrix, annot=True, fmt='.2f', cmap='crest')\n",
    "    \n",
    "    # Set custom tick labels\n",
    "    ax.set_xticklabels(['Real', 'Fake'], rotation=0)\n",
    "    ax.set_yticklabels(['Real', 'Fake'], rotation=0)\n",
    "\n",
    "    plt.title('Confussion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load('train_dataset.pt')\n",
    "val_dataset = torch.load('test_dataset.pt')\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "dataloaders = {'train':dataloader, \n",
    "               'val': val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train folds: 3\n",
      "Total val folds: 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "\n",
    "# Load pre-saved datasets\n",
    "dataset = torch.load('train_dataset.pt')\n",
    "val_dataset = torch.load('test_dataset.pt')\n",
    "\n",
    "# Create DataLoaders\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Combine both train and validation datasets for K-Fold Cross-Validation\n",
    "dataset_concat = torch.utils.data.ConcatDataset([dataset, val_dataset])\n",
    "\n",
    "# Set K-Fold parameters\n",
    "k_folds = 3\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "# Dictionary to hold train and validation DataLoaders for each fold\n",
    "folds = {'train': [], 'val': []}\n",
    "\n",
    "# Initialize K-Fold Cross-Validation\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# Split the dataset and create DataLoaders for each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset_concat)):\n",
    "    train_subset = Subset(dataset_concat, train_idx)\n",
    "    val_subset = Subset(dataset_concat, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    folds['train'].append(train_loader)\n",
    "    folds['val'].append(val_loader)\n",
    "\n",
    "# Print number of folds\n",
    "print(f\"Total train folds: {len(folds['train'])}\")\n",
    "print(f\"Total val folds: {len(folds['val'])}\")\n",
    "\n",
    "def train_kfold(model, folds, optim, criterion, epochs, device='cuda', display_prints=True, tuning=False):\n",
    "    fold_results = []\n",
    "\n",
    "    for fold in range(len(folds['train'])):\n",
    "        print(f\"Training fold {fold+1}/{len(folds['train'])}\")\n",
    "        train_loader = folds['train'][fold]\n",
    "        val_loader = folds['val'][fold]\n",
    "        model.apply(reset_weights)\n",
    "        optim.zero_grad()\n",
    "\n",
    "        best_val_loss = float('inf')  # Track best validation loss for saving the model\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            if display_prints:\n",
    "                print(f'Epoch {epoch}/{epochs - 1}')\n",
    "                print('-'*10)\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_correct = 0.0\n",
    "                for inputs, labels in (train_loader if phase == 'train' else val_loader):\n",
    "                    if device == 'cuda':\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                    labels = labels.float()\n",
    "                    optim.zero_grad()\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        output = model(inputs)\n",
    "                        loss = criterion(output, labels)\n",
    "                        acc = (torch.where(output >= 0.5, 1, 0) == labels).sum()\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optim.step()\n",
    "                    del inputs, labels, output\n",
    "                    running_loss += loss.item()\n",
    "                    running_correct += acc.item()\n",
    "                epoch_loss = running_loss / len(train_loader if phase == 'train' else val_loader)\n",
    "                epoch_acc = running_correct / len(train_loader.dataset if phase == 'train' else val_loader.dataset)\n",
    "                if display_prints:\n",
    "                    print(f'{phase} Loss: {epoch_loss:.3f} Acc: {epoch_acc:.3f}')\n",
    "                if tuning and phase == \"val\":\n",
    "                    train.report({\"loss\": epoch_loss.item(), \"accuracy\": epoch_acc.item()})\n",
    "\n",
    "            # Save the best model for this fold based on validation loss\n",
    "            if phase == 'val' and epoch_loss < best_val_loss:\n",
    "                best_val_loss = epoch_loss\n",
    "                torch.save(model.state_dict(), f'best_model_fold_{fold+1}.pth')\n",
    "                print(f\"Best model for fold {fold+1} saved!\")\n",
    "\n",
    "        fold_results.append({\n",
    "            'fold': fold,\n",
    "            'train_loss': epoch_loss,\n",
    "            'train_accuracy': epoch_acc\n",
    "        })\n",
    "\n",
    "    # Calculate average loss and accuracy across all folds\n",
    "    avg_train_loss = sum([result['train_loss'] for result in fold_results]) / len(fold_results)\n",
    "    avg_train_accuracy = sum([result['train_accuracy'] for result in fold_results]) / len(fold_results)\n",
    "\n",
    "    print(f\"Average Train Loss: {avg_train_loss:.3f}\")\n",
    "    print(f\"Average Train Accuracy: {avg_train_accuracy:.3f}\")\n",
    "\n",
    "    # Save the final model after all folds\n",
    "    torch.save(model.state_dict(), 'final_model.pth')\n",
    "    print(\"Final model saved!\")\n",
    "\n",
    "    return model, fold_results\n",
    "# Function to reset the weights of the model\n",
    "def reset_weights(m):\n",
    "    if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "        m.reset_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /home/zeus/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 289MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/3\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m      5\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[0;32m----> 6\u001b[0m out_model, result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_kfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m result\n",
      "Cell \u001b[0;32mIn[12], line 71\u001b[0m, in \u001b[0;36mtrain_kfold\u001b[0;34m(model, folds, optim, criterion, epochs, device, display_prints, tuning)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m (train_loader \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m val_loader):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 71\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     73\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/cuda/__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "from models.resnet50 import ResNet50DeepFake\n",
    "model = ResNet50DeepFake(hidden_dim=32, reduced_feature_dim=512)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCELoss()\n",
    "out_model, result = train_kfold(model, folds, optimizer, criterion, 10)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
